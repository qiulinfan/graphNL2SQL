% Unofficial Umich Poster template.
% A fork of the MSU template https://www.overleaf.com/latex/templates/an-unofficial-poster-template-for-michigan-state-university/wnymbgpxnnwd
% which is a fork of https://www.overleaf.com/latex/templates/an-unofficial-poster-template-for-new-york-university/krgqtqmzdqhg
% which is a fork of https://github.com/anishathalye/gemini
% also refer to https://github.com/k4rtik/uchicago-poster



\documentclass[final, 15pt]{beamer}

% ====================
% Packages
% ====================
\usepackage[T1]{fontenc}
 \usepackage[utf8]{luainputenc}
\usepackage{lmodern}
\usepackage[size=custom, width=122,height=91, scale=1.2]{beamerposter}
\usetheme{gemini}
\usecolortheme{msu}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.14}
\usepackage{anyfontsize}

% ====================
% Lengths
% ====================

% If you have N columns, choose \sepwidth and \colwidth such that
% (N+1)*\sepwidth + N*\colwidth = \paperwidth

\newlength{\sepwidth}
\newlength{\colwidth}
\setlength{\sepwidth}{0.025\paperwidth}
\setlength{\colwidth}{0.3\paperwidth}

\newcommand{\separatorcolumn}{\begin{column}{\sepwidth}\end{column}}

% ====================
% Title
% ====================

\title{Fine-tuning Small LLMs with Graph-Modeled Schemas for Multi-table NL2SQL}

\author{Zhanhao Liu and Qiulin Fan}

\institute[shortinst]{Department of Electrical Engineering and Computer Science, University of Michigan}

% ====================
% Footer (optional)
% ====================

\footercontent{
  \href{https://github.com}{University of Michigan} \hfill
EECS 595 \hfill
  \href{mailto:youremail@msu.edu}{zhanhaol@umich.edu}}
% (can be left out to remove footer)

% ====================
% Logo (optional)
% ====================

% use this to include logos on the left and/or right side of the header:
% Left: institution
 \logoright{\includegraphics[height=5cm]{logos/blockM.png}}
% Right: funding agencies and other affilations 
%\logoright{\includegraphics[height=7cm]{logos/NSF.eps}}
% ====================
% Body
% ====================

\begin{document}


\begin{frame}[t]

\begin{columns}[t]
\separatorcolumn

\begin{column}{\colwidth}
  \begin{block}{Introduction}
    Early NL2SQL systems relied on task-specific encoder–decoder models such as Seq2SQL, SQLNet, and RAT-SQL, which achieved strong benchmark performance but suffered from \textbf{limited generalization due to small model size} and lack of large-scale language pretraining. These models lack general language modeling ability and exhibit \textbf{poor few-shot generalization} upon domains and databases they have not seen, even simple ones. When confronted with \textbf{complex queries (e.g, multi-table Join)}, these models often fail to transfer learned knowledge. While recent large language models significantly improve NL2SQL performance, they rely heavily on closed-source models and incur substantial computational and memory costs, making domain-specific fine-tuning impractical. In this work, we explore how small-parameter LLMs (3–8B) can be fine-tuned to achieve competitive NL2SQL performance on complex queries. We propose \textbf{strengthening structural reasoning through graph-based schema modeling} to better capture multi-table relationships and bridge the gap between natural language and database structure.
  \end{block}
%\mbox{}\\
  
\begin{block}{Dataset and Model Selection}
\textbf{Datasets:}
\begin{itemize}
    \item \textbf{WikiSQL}: Large-scale NL2SQL benchmark with single-table queries and high-quality natural language–SQL annotations.
    \item \textbf{Spider}: Cross-domain dataset with complex, multi-table queries across diverse database schemas.
\end{itemize}

\textbf{Why These Datasets:}
\begin{itemize}
    \item \textbf{Multi-table Reasoning}: Spider explicitly targets multi-table joins and nested query structures, directly matching our project focus.
    \item \textbf{Difficulty Stratification}: Spider provides labeled difficulty levels for fine-grained evaluation across increasing complexity.
    \item \textbf{Standard Benchmarking}: WikiSQL is widely used in prior work, enabling direct and fair performance comparison.
\end{itemize}
\begin{figure}
    \centering
    \includegraphics[width=0.42\linewidth]{example.png}
     \hspace{0.5em} % 1em
    \includegraphics[width=0.38\linewidth]{example_json.png}
    \caption{Example question with its json format in Spider.}
    \label{fig:example}
\end{figure}

\textbf{Base and Baseline Models:}

We develop our graph-enhanced NL2SQL approach on \textbf{Qwen2.5-7B-Instruct}, a small-parameter large language model from the Qwen family with approximately 7B parameters. This model balances computational efficiency with strong language understanding capabilities, making it suitable for domain-specific fine-tuning.

For baseline comparisons, we evaluate against task-specific models: \textbf{T5-base fine-tuned on WikiSQL} (\texttt{mrm8488/t5-base-finetuned-wikiSQL}, 56\% accuracy) for single-table queries, and \textbf{T5-Large fine-tuned on Spider} (\texttt{gaussalgo/T5-LM-Large-text2sql-spider}, 41.3\% accuracy) for complex multi-table queries. These baselines, while achieving reasonable in-domain performance, suffer from limited generalization beyond their training datasets—demonstrating the need for enhanced structural reasoning capabilities.

\end{block}
\end{column}

\separatorcolumn

\begin{column}{\colwidth}

\begin{block}{Graph-Modeling Designs}

\textbf{Graph Construction:} Let $\mathcal{D} = (\mathcal{T}, \mathcal{F})$ denote a database schema, where $\mathcal{T} = \{T_1, \ldots, T_n\}$ is the set of tables and $\mathcal{F} \subseteq \mathcal{T} \times \mathcal{T}$ represents foreign-key relationships. For each table $T_i$, let $C_i = \{c_{i,1}, \ldots, c_{i,m_i}\}$ denote its columns.

We model the schema as a heterogeneous graph $G = (V, E)$ where:
\begin{itemize}
\item $V = V_{\text{table}} \cup V_{\text{col}}$ with $V_{\text{table}} = \{v_{T_i} : T_i \in \mathcal{T}\}$ and $V_{\text{col}} = \{v_{c_{i,j}} : c_{i,j} \in C_i, T_i \in \mathcal{T}\}$
\item Edge set $E = E_{\text{contain}} \cup E_{\text{FK}} \cup E_{\text{sem}}$ where:
  \begin{itemize}
  \item $E_{\text{contain}} = \{(v_{T_i}, v_{c_{i,j}}) : c_{i,j} \in C_i\}$ (table-column containment)
  \item $E_{\text{FK}} = \{(v_{c}, v_{c'}) : c \text{ references } c'\}$ (foreign-key edges)
  \item $E_{\text{sem}} = \{(v_c, v_{c'}) : \text{sim}(c, c') > \tau\}$ (semantic similarity edges)
  \end{itemize}
\end{itemize}

\textbf{Semantic Similarity:} Column embeddings are computed via a pretrained encoder $\phi: \text{String} \to \mathbb{R}^d$. Two columns $c, c'$ are connected if $\cos(\phi(c), \phi(c')) > \tau$ for threshold $\tau \in [0,1]$.

\textbf{Typed Graphs:} Each node $v \in V$ and edge $e \in E$ is annotated with type labels $\ell_V(v) \in \{\texttt{table}, \texttt{column}, \texttt{pk}\}$ and $\ell_E(e) \in \{\texttt{contain}, \texttt{fk}, \texttt{sem}\}$.

\end{block}

\begin{figure}
    \centering
\includegraphics[width=1\linewidth]{figure1.png}
    \caption{Demonstration of Graph-Modeling Designs }
    \label{fig:placeholder}
\end{figure}


\textbf{Graph Linearization:} The constructed graph $G$ is serialized into a structured text representation using XML-style tags that preserve node types, edge types, and topological structure. \\Training input is $$x = \text{Concat}(q, \text{SchemaText}, s)$$ where $s$ is the graph serialization.\\\\
\textbf{Two Key Extensions:}
\begin{enumerate}
\item \textbf{Semantic Edges} connect schema elements with high embedding similarity (e.g., \textit{Birthday} $\leftrightarrow$ \textit{DOB}), improving generalization across naming variations.
\item \textbf{Typed Graphs} annotate all nodes and edges with explicit type labels, enabling the LLM to distinguish between tables, columns, primary keys, foreign keys, and different relationship types during reasoning.
\end{enumerate}


\begin{figure}
    \centering
\includegraphics[width=0.6\linewidth]{simple.png}
    \caption{A simple typed graph.}
    \label{fig:simple}
\end{figure}

\end{column}



\separatorcolumn
\begin{column}{\colwidth}
\begin{block}{Model and Training}

\textbf{Model Architecture:} We fine-tune Qwen-2.5-7B-Instruct, a decoder-only LLM with $\approx 7 \times 10^9$ parameters, using Low-Rank Adaptation (LoRA) with rank $r = 16$ and scaling factor $\alpha = 32$.

\textbf{Training Objective:} Given natural language query $q$, schema $\mathcal{D}$, and graph $G$, we optimize the conditional log-likelihood:
\[
\mathcal{L}(\theta) = -\sum_{i=1}^{|y|} \log p_\theta(y_i \mid y_{<i}, q, \mathcal{D}, G)
\]
where $y = (y_1, \ldots, y_{|y|})$ is the target SQL query tokenized into subwords.

\end{block}



% \begin{block}{Evaluation and Baselines}

% \textbf{Input Format:} The model receives a structured prompt:
% \begin{center}
% \small
% \texttt{[INST] Question: } $q$ \texttt{ Schema: } $\mathcal{D}_{\text{text}}$ \texttt{ Graph: } $G_{\text{text}}$ \texttt{ [/INST]}
% \end{center}
% where $\mathcal{D}_{\text{text}}$ is a textual schema description and $G_{\text{text}}$ is the linearized graph representation.

% \textbf{Evaluation Metrics:}
% \begin{itemize}
% \item \textbf{Logical Form Accuracy (LF)}: Exact match between normalized predicted and gold SQL after lowercasing, whitespace removal, and quote normalization.
% \item \textbf{Execution Accuracy (EX)}: Agreement between query results when both predicted and gold SQL are executed on the database.
% \end{itemize}

% \textbf{Baselines:} We compare against T5-base fine-tuned on WikiSQL (single-table) and T5-base fine-tuned on Spider (multi-table) to assess performance gains from graph-enhanced prompting on a modern LLM architecture.

% \end{block}

  \begin{block}{Result}
In this project, we adopt a hybrid fine-tuning strategy based on a 7B Qwen base model using both the WikiSQL and Spider datasets. We apply LoRA to the 7B Qwen model, introducing approximately 5\%additional trainable parameters (about 20M), while keeping the remaining backbone parameters frozen during training. Both datasets are preprocessed to incorporate graph-structured schema representations as input. Since WikiSQL is relatively simpler and more straightforward than Spider, and the 7B Qwen model is a general-purpose language model not originally specialized for NL2SQL tasks, we first fine-tune the model on the WikiSQL dataset to warm up the training. We then further fine-tune the model on the Spider dataset for three additional epochs. In total, we use 11,293 training examples, consisting of 4,293 WikiSQL samples and 7,000 Spider samples, which are further split into training, validation, and test sets. The total training process takes approximately five hours and achieves around 44.3\% test accuracy, outperforming the baseline T5 models.
\begin{table}[!htbp]
\centering
\caption{Evaluation results of NL2SQL models on Spider datasets.}
\label{tab:evaluation-results}
\renewcommand{\arraystretch}{1.1}
% 缩放表格到页面宽度
\resizebox{0.6\linewidth}{!}{
\begin{tabular}{@{}l l c@{}}
\toprule
\textbf{Model} & \textbf{Accuracy (\%)} \\
\midrule
\texttt{Fine tuned Qwen} & 44.3\\
 \texttt{gaussalgo/T5-LM-Large-text2sql-spider} & 41.3 \\
\texttt{mrm8488/t5-base-finetuned-wikiSQL}     & 23.0 \\
\bottomrule
\end{tabular}
}
\end{table}
\begin{figure}
    \centering
\includegraphics[width=0.45\linewidth]{train_loss.png}
\hspace{0.5em} % 1em
\includegraphics[width=0.45\linewidth]{grad.png}
    \caption{Training Loss and Grad Norm graph.}
    \label{fig:trainloss}
\end{figure}
  \end{block}

 \begin{block}{Future Work}
\begin{itemize}
  \item \textbf{Execution-Guided Decoding (EGD):} At inference, generate candidate set $\mathcal{C}_k$ via beam search, evaluate with execution oracle $\mathcal{E}(y) = (c, r)$ (compilability, correctness), and select
  \[
  \hat{y} \in \arg\max_{y \in \mathcal{C}_k} \Big( r(y),\, c(y),\, \log p_\theta(y \mid x) \Big)
  \]
  lexicographically. This improves execution accuracy without retraining.
  \item \textbf{Direct Graph Embeddings:} Replace text linearization with learned GNN encodings $\mathbf{h}_\mathcal{G}$ to capture relational structure more effectively.
  \item \textbf{Adaptive Graph Construction:} Balance semantic enrichment and noise.
\end{itemize}
  \end{block}

\end{column}

\separatorcolumn
\end{columns}
\end{frame}

\end{document}