{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXe1CK42hIIZ"
      },
      "source": [
        "## Git clone\n",
        "\n",
        "Cloning this repository after you download this ipynb file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCrvcSp_u7dV",
        "outputId": "b48981c1-232c-4030-c485-cb6834b15a9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'graphNL2SQL'...\n",
            "remote: Enumerating objects: 145, done.\u001b[K\n",
            "remote: Counting objects: 100% (145/145), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 145 (delta 60), reused 115 (delta 30), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (145/145), 3.26 MiB | 47.67 MiB/s, done.\n",
            "Resolving deltas: 100% (60/60), done.\n",
            "/content/graphNL2SQL\n"
          ]
        }
      ],
      "source": [
        "import getpass, os\n",
        "\n",
        "#token = getpass.getpass(\"input Token: \")\n",
        "username = \"qiulinfan\"\n",
        "owner = \"qiulinfan\"\n",
        "repo = \"graphNL2SQL\"\n",
        "\n",
        "#os.environ[\"GITHUB_TOKEN\"] = token\n",
        "#os.environ[\"GITHUB_USER\"] = username\n",
        "os.environ[\"GITHUB_OWNER\"] = owner\n",
        "os.environ[\"GITHUB_REPO\"] = repo\n",
        "\n",
        "!git clone https://github.com/${GITHUB_OWNER}/${GITHUB_REPO}.git\n",
        "%cd graphNL2SQL/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZXry0lbkcI9",
        "outputId": "f660c34e-6db8-4a55-e21a-9c31cb2762e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9n2DGGJBlW-"
      },
      "source": [
        "## Download and preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-IJRQ-uvTTI",
        "outputId": "2b5a223b-b8d1-4825-8411-eec8b520924c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "NL2SQL Dataset Downloader\n",
            "============================================================\n",
            "\n",
            "[1/2] WikiSQL Dataset\n",
            "----------------------------------------\n",
            "Downloading WikiSQL dataset...\n",
            "WikiSQL: 100% 26.2M/26.2M [00:00<00:00, 306MB/s]\n",
            "Extracting WikiSQL...\n",
            "/content/graphNL2SQL/scripts/download_data.py:54: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
            "  tar.extractall(DATA_DIR)\n",
            "WikiSQL extracted to /content/graphNL2SQL/data/wikisql\n",
            "\n",
            "[2/2] Spider Dataset\n",
            "----------------------------------------\n",
            "Downloading Spider dataset from Google Drive...\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1403EGqzIDoHMdQF4c9Bkyl7dZLZ5Wt6J\n",
            "From (redirected): https://drive.google.com/uc?id=1403EGqzIDoHMdQF4c9Bkyl7dZLZ5Wt6J&confirm=t&uuid=71e71056-d1da-47ad-873c-6a6f2e9cf79e\n",
            "To: /content/graphNL2SQL/data/spider_data.zip\n",
            "100% 206M/206M [00:02<00:00, 86.6MB/s]\n",
            "Extracting Spider dataset...\n",
            "Renamed spider_data/ -> spider/\n",
            "Spider extracted to /content/graphNL2SQL/data/spider\n",
            "\n",
            "============================================================\n",
            "Dataset Verification\n",
            "============================================================\n",
            "WikiSQL train: 56355 entries\n",
            "WikiSQL dev: 8421 entries\n",
            "WikiSQL test: 15878 entries\n",
            "WikiSQL train_tables: 18585 entries\n",
            "WikiSQL dev_tables: 2716 entries\n",
            "WikiSQL test_tables: 5230 entries\n",
            "Spider train: 7000 entries\n",
            "Spider dev: 1034 entries\n",
            "Spider tables: 166 entries\n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "!python scripts/download_data.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noRs_T-MvxOj",
        "outputId": "4a5c5b3e-d0cd-4374-e230-0e7d49e61c70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing WikiSQL train split...\n",
            "Sampling 2000 balanced WikiSQL examples from train...\n",
            "  Pattern distribution in dataset:\n",
            "    where_only: 40598\n",
            "    count: 5114\n",
            "    min: 3231\n",
            "    max: 3161\n",
            "    avg: 2201\n",
            "    sum: 2042\n",
            "    select_only: 8\n",
            "  Sampled 1722 examples\n",
            "WikiSQL: 100% 1722/1722 [00:00<00:00, 41867.67it/s]\n",
            "Processed 1722 WikiSQL examples\n",
            "Processing WikiSQL dev split...\n",
            "Sampling 400 balanced WikiSQL examples from dev...\n",
            "  Pattern distribution in dataset:\n",
            "    where_only: 6017\n",
            "    count: 779\n",
            "    max: 507\n",
            "    min: 468\n",
            "    avg: 329\n",
            "    sum: 321\n",
            "    select_only: 0\n",
            "  Sampled 399 examples\n",
            "WikiSQL: 100% 399/399 [00:00<00:00, 44647.63it/s]\n",
            "Processed 399 WikiSQL examples\n",
            "Saved 1722 examples to /content/graphNL2SQL/training_data/wikisql_train.jsonl\n",
            "Saved 399 examples to /content/graphNL2SQL/training_data/wikisql_dev.jsonl\n",
            "Processing Spider train split...\n",
            "Spider: 100% 7000/7000 [00:00<00:00, 55999.57it/s]\n",
            "Processed 7000 Spider examples\n",
            "  Multi-table examples: 7000\n",
            "  Examples with JOIN: 2783\n",
            "Processing Spider dev split...\n",
            "Spider: 100% 1034/1034 [00:00<00:00, 120876.01it/s]\n",
            "Processed 1034 Spider examples\n",
            "  Multi-table examples: 1034\n",
            "  Examples with JOIN: 408\n",
            "Saved 7000 examples to /content/graphNL2SQL/training_data/spider_train.jsonl\n",
            "Saved 1034 examples to /content/graphNL2SQL/training_data/spider_dev.jsonl\n",
            "\n",
            "Saving combined training data...\n",
            "Saved 8722 examples to /content/graphNL2SQL/training_data/train.jsonl\n",
            "Saved 1433 examples to /content/graphNL2SQL/training_data/dev.jsonl\n",
            "Saved 8722 examples to /content/graphNL2SQL/training_data/train_alpaca.json\n",
            "Saved 1433 examples to /content/graphNL2SQL/training_data/dev_alpaca.json\n",
            "Saved 8722 examples to /content/graphNL2SQL/training_data/train_chat.json\n",
            "Saved 1433 examples to /content/graphNL2SQL/training_data/dev_chat.json\n",
            "\n",
            "============================================================\n",
            "TRAINING DATA SUMMARY\n",
            "============================================================\n",
            "Total training examples: 8722\n",
            "Total dev examples: 1433\n",
            "Output directory: /content/graphNL2SQL/training_data\n",
            "Linearization style: structured\n",
            "\n",
            "Training set breakdown:\n",
            "  WikiSQL: 1722\n",
            "  Spider: 7000\n",
            "\n",
            "Complexity stats:\n",
            "  Multi-table examples: 7000 (80.3%)\n",
            "  Examples with JOIN: 2783 (31.9%)\n"
          ]
        }
      ],
      "source": [
        "!python scripts/prepare_training_data.py --wikisql-balanced 2000 --spider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "id": "98X0gjZahsO_",
        "outputId": "315d2009-c02f-4f71-e406-9cab263169ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [DATABASE]\\ndepartment_management\\n\\n[TABLES]\\ndepartment:\\n    Department_ID (PK)\\n    Name\\n    Creation\\n    Ranking\\n    Budget_in_Billions\\n    Num_Employees\\nhead:\\n    head_ID (PK)\\n    name\\n    born_state\\n    age\\nmanagement:\\n    department_ID (PK, FK)\\n    head_ID (FK)\\n    temporary_acting\\n\\n[FOREIGN KEYS]\\nmanagement.head_ID -> head.head_ID\\nmanagement.department_ID -> department.Department_ID\n",
              "1    [DATABASE]\\ndepartment_management\\n\\n[TABLES]\\ndepartment:\\n    Department_ID (PK)\\n    Name\\n    Creation\\n    Ranking\\n    Budget_in_Billions\\n    Num_Employees\\nhead:\\n    head_ID (PK)\\n    name\\n    born_state\\n    age\\nmanagement:\\n    department_ID (PK, FK)\\n    head_ID (FK)\\n    temporary_acting\\n\\n[FOREIGN KEYS]\\nmanagement.head_ID -> head.head_ID\\nmanagement.department_ID -> department.Department_ID\n",
              "2    [DATABASE]\\ndepartment_management\\n\\n[TABLES]\\ndepartment:\\n    Department_ID (PK)\\n    Name\\n    Creation\\n    Ranking\\n    Budget_in_Billions\\n    Num_Employees\\nhead:\\n    head_ID (PK)\\n    name\\n    born_state\\n    age\\nmanagement:\\n    department_ID (PK, FK)\\n    head_ID (FK)\\n    temporary_acting\\n\\n[FOREIGN KEYS]\\nmanagement.head_ID -> head.head_ID\\nmanagement.department_ID -> department.Department_ID\n",
              "3    [DATABASE]\\ndepartment_management\\n\\n[TABLES]\\ndepartment:\\n    Department_ID (PK)\\n    Name\\n    Creation\\n    Ranking\\n    Budget_in_Billions\\n    Num_Employees\\nhead:\\n    head_ID (PK)\\n    name\\n    born_state\\n    age\\nmanagement:\\n    department_ID (PK, FK)\\n    head_ID (FK)\\n    temporary_acting\\n\\n[FOREIGN KEYS]\\nmanagement.head_ID -> head.head_ID\\nmanagement.department_ID -> department.Department_ID\n",
              "4    [DATABASE]\\ndepartment_management\\n\\n[TABLES]\\ndepartment:\\n    Department_ID (PK)\\n    Name\\n    Creation\\n    Ranking\\n    Budget_in_Billions\\n    Num_Employees\\nhead:\\n    head_ID (PK)\\n    name\\n    born_state\\n    age\\nmanagement:\\n    department_ID (PK, FK)\\n    head_ID (FK)\\n    temporary_acting\\n\\n[FOREIGN KEYS]\\nmanagement.head_ID -> head.head_ID\\nmanagement.department_ID -> department.Department_ID\n",
              "5    [DATABASE]\\ndepartment_management\\n\\n[TABLES]\\ndepartment:\\n    Department_ID (PK)\\n    Name\\n    Creation\\n    Ranking\\n    Budget_in_Billions\\n    Num_Employees\\nhead:\\n    head_ID (PK)\\n    name\\n    born_state\\n    age\\nmanagement:\\n    department_ID (PK, FK)\\n    head_ID (FK)\\n    temporary_acting\\n\\n[FOREIGN KEYS]\\nmanagement.head_ID -> head.head_ID\\nmanagement.department_ID -> department.Department_ID\n",
              "6    [DATABASE]\\ndepartment_management\\n\\n[TABLES]\\ndepartment:\\n    Department_ID (PK)\\n    Name\\n    Creation\\n    Ranking\\n    Budget_in_Billions\\n    Num_Employees\\nhead:\\n    head_ID (PK)\\n    name\\n    born_state\\n    age\\nmanagement:\\n    department_ID (PK, FK)\\n    head_ID (FK)\\n    temporary_acting\\n\\n[FOREIGN KEYS]\\nmanagement.head_ID -> head.head_ID\\nmanagement.department_ID -> department.Department_ID\n",
              "7    [DATABASE]\\ndepartment_management\\n\\n[TABLES]\\ndepartment:\\n    Department_ID (PK)\\n    Name\\n    Creation\\n    Ranking\\n    Budget_in_Billions\\n    Num_Employees\\nhead:\\n    head_ID (PK)\\n    name\\n    born_state\\n    age\\nmanagement:\\n    department_ID (PK, FK)\\n    head_ID (FK)\\n    temporary_acting\\n\\n[FOREIGN KEYS]\\nmanagement.head_ID -> head.head_ID\\nmanagement.department_ID -> department.Department_ID\n",
              "8    [DATABASE]\\ndepartment_management\\n\\n[TABLES]\\ndepartment:\\n    Department_ID (PK)\\n    Name\\n    Creation\\n    Ranking\\n    Budget_in_Billions\\n    Num_Employees\\nhead:\\n    head_ID (PK)\\n    name\\n    born_state\\n    age\\nmanagement:\\n    department_ID (PK, FK)\\n    head_ID (FK)\\n    temporary_acting\\n\\n[FOREIGN KEYS]\\nmanagement.head_ID -> head.head_ID\\nmanagement.department_ID -> department.Department_ID\n",
              "9    [DATABASE]\\ndepartment_management\\n\\n[TABLES]\\ndepartment:\\n    Department_ID (PK)\\n    Name\\n    Creation\\n    Ranking\\n    Budget_in_Billions\\n    Num_Employees\\nhead:\\n    head_ID (PK)\\n    name\\n    born_state\\n    age\\nmanagement:\\n    department_ID (PK, FK)\\n    head_ID (FK)\\n    temporary_acting\\n\\n[FOREIGN KEYS]\\nmanagement.head_ID -> head.head_ID\\nmanagement.department_ID -> department.Department_ID\n",
              "Name: schema, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>schema</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[DATABASE]\\ndepartment_management\\n\\n[TABLES]\\ndepartment:\\n    Department_ID (PK)\\n    Name\\n    Creation\\n    Ranking\\n    Budget_in_Billions\\n    Num_Employees\\nhead:\\n    head_ID (PK)\\n    name\\n    born_state\\n    age\\nmanagement:\\n    department_ID (PK, FK)\\n    head_ID (FK)\\n    temporary_acting\\n\\n[FOREIGN KEYS]\\nmanagement.head_ID -&gt; head.head_ID\\nmanagement.department_ID -&gt; department.Department_ID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[DATABASE]\\ndepartment_management\\n\\n[TABLES]\\ndepartment:\\n    Department_ID (PK)\\n    Name\\n    Creation\\n    Ranking\\n    Budget_in_Billions\\n    Num_Employees\\nhead:\\n    head_ID (PK)\\n    name\\n    born_state\\n    age\\nmanagement:\\n    department_ID (PK, FK)\\n    head_ID (FK)\\n    temporary_acting\\n\\n[FOREIGN KEYS]\\nmanagement.head_ID -&gt; head.head_ID\\nmanagement.department_ID -&gt; department.Department_ID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[DATABASE]\\ndepartment_management\\n\\n[TABLES]\\ndepartment:\\n    Department_ID (PK)\\n    Name\\n    Creation\\n    Ranking\\n    Budget_in_Billions\\n    Num_Employees\\nhead:\\n    head_ID (PK)\\n    name\\n    born_state\\n    age\\nmanagement:\\n    department_ID (PK, FK)\\n    head_ID (FK)\\n    temporary_acting\\n\\n[FOREIGN KEYS]\\nmanagement.head_ID -&gt; head.head_ID\\nmanagement.department_ID -&gt; department.Department_ID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[DATABASE]\\ndepartment_management\\n\\n[TABLES]\\ndepartment:\\n    Department_ID (PK)\\n    Name\\n    Creation\\n    Ranking\\n    Budget_in_Billions\\n    Num_Employees\\nhead:\\n    head_ID (PK)\\n    name\\n    born_state\\n    age\\nmanagement:\\n    department_ID (PK, FK)\\n    head_ID (FK)\\n    temporary_acting\\n\\n[FOREIGN KEYS]\\nmanagement.head_ID -&gt; head.head_ID\\nmanagement.department_ID -&gt; department.Department_ID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[DATABASE]\\ndepartment_management\\n\\n[TABLES]\\ndepartment:\\n    Department_ID (PK)\\n    Name\\n    Creation\\n    Ranking\\n    Budget_in_Billions\\n    Num_Employees\\nhead:\\n    head_ID (PK)\\n    name\\n    born_state\\n    age\\nmanagement:\\n    department_ID (PK, FK)\\n    head_ID (FK)\\n    temporary_acting\\n\\n[FOREIGN KEYS]\\nmanagement.head_ID -&gt; head.head_ID\\nmanagement.department_ID -&gt; department.Department_ID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[DATABASE]\\ndepartment_management\\n\\n[TABLES]\\ndepartment:\\n    Department_ID (PK)\\n    Name\\n    Creation\\n    Ranking\\n    Budget_in_Billions\\n    Num_Employees\\nhead:\\n    head_ID (PK)\\n    name\\n    born_state\\n    age\\nmanagement:\\n    department_ID (PK, FK)\\n    head_ID (FK)\\n    temporary_acting\\n\\n[FOREIGN KEYS]\\nmanagement.head_ID -&gt; head.head_ID\\nmanagement.department_ID -&gt; department.Department_ID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[DATABASE]\\ndepartment_management\\n\\n[TABLES]\\ndepartment:\\n    Department_ID (PK)\\n    Name\\n    Creation\\n    Ranking\\n    Budget_in_Billions\\n    Num_Employees\\nhead:\\n    head_ID (PK)\\n    name\\n    born_state\\n    age\\nmanagement:\\n    department_ID (PK, FK)\\n    head_ID (FK)\\n    temporary_acting\\n\\n[FOREIGN KEYS]\\nmanagement.head_ID -&gt; head.head_ID\\nmanagement.department_ID -&gt; department.Department_ID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[DATABASE]\\ndepartment_management\\n\\n[TABLES]\\ndepartment:\\n    Department_ID (PK)\\n    Name\\n    Creation\\n    Ranking\\n    Budget_in_Billions\\n    Num_Employees\\nhead:\\n    head_ID (PK)\\n    name\\n    born_state\\n    age\\nmanagement:\\n    department_ID (PK, FK)\\n    head_ID (FK)\\n    temporary_acting\\n\\n[FOREIGN KEYS]\\nmanagement.head_ID -&gt; head.head_ID\\nmanagement.department_ID -&gt; department.Department_ID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[DATABASE]\\ndepartment_management\\n\\n[TABLES]\\ndepartment:\\n    Department_ID (PK)\\n    Name\\n    Creation\\n    Ranking\\n    Budget_in_Billions\\n    Num_Employees\\nhead:\\n    head_ID (PK)\\n    name\\n    born_state\\n    age\\nmanagement:\\n    department_ID (PK, FK)\\n    head_ID (FK)\\n    temporary_acting\\n\\n[FOREIGN KEYS]\\nmanagement.head_ID -&gt; head.head_ID\\nmanagement.department_ID -&gt; department.Department_ID</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[DATABASE]\\ndepartment_management\\n\\n[TABLES]\\ndepartment:\\n    Department_ID (PK)\\n    Name\\n    Creation\\n    Ranking\\n    Budget_in_Billions\\n    Num_Employees\\nhead:\\n    head_ID (PK)\\n    name\\n    born_state\\n    age\\nmanagement:\\n    department_ID (PK, FK)\\n    head_ID (FK)\\n    temporary_acting\\n\\n[FOREIGN KEYS]\\nmanagement.head_ID -&gt; head.head_ID\\nmanagement.department_ID -&gt; department.Department_ID</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.set_option(\"display.max_rows\", None)   # 不省略行\n",
        "pd.set_option(\"display.max_columns\", None)  # 不省略列\n",
        "pd.set_option(\"display.max_colwidth\", None) # 不省略内容长度\n",
        "df = pd.read_json(\"training_data/spider_train.jsonl\", lines=True)\n",
        "df['schema'][0:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "Vsaua707P2dA",
        "outputId": "7c198af1-dac1-4716-efb3-8f65c6b7f825"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                                            [TABLES]\\nCoolBrands_branding_initiative:\\n    Rank (PK)\\n    2008\\n    2009\\n    2010\\n    2011\\n    2012\\n    2013\n",
              "1                   [TABLES]\\nUnited_States_House_of_Representatives_elections_1998:\\n    District (PK)\\n    Incumbent\\n    Party\\n    First elected\\n    Results\\n    Candidates\n",
              "2                                                                         [TABLES]\\nCircuit_Trois_Rivières:\\n    Year (PK)\\n    Date\\n    Driver\\n    Team\\n    Distance/Duration\n",
              "3                                                          [TABLES]\\n1987_World_Rhythmic_Gymnastics_Championships:\\n    Place (PK)\\n    Name\\n    All Around\\n    Hoop\\n    Total\n",
              "4                                                      [TABLES]\\nCentral_Murray_Football_League:\\n    Central Murray (PK)\\n    Wins\\n    Byes\\n    Losses\\n    Draws\\n    Against\n",
              "5    [TABLES]\\nCashmere_Mafia:\\n    Episode (PK)\\n    Rating\\n    Share\\n    Rating/Share (18-49)\\n    Viewers (millions)\\n    Rank (timeslot)\\n    Rank (night)\\n    Rank (week)\n",
              "6                                                                    [TABLES]\\n2008_Brazilian_Grand_Prix:\\n    Driver (PK)\\n    Constructor\\n    Laps\\n    Time/Retired\\n    Grid\n",
              "7       [TABLES]\\nUkraine_in_the_Eurovision_Song_Contest:\\n    Year(s) (PK)\\n    Television commentator\\n    Dual Television commentator\\n    Radio commentator\\n    Spokesperson\n",
              "8                                                                     [TABLES]\\n193940_New_York_Rangers_season:\\n    Game (PK)\\n    February\\n    Opponent\\n    Score\\n    Record\n",
              "9                                                          [TABLES]\\n1987_World_Rhythmic_Gymnastics_Championships:\\n    Place (PK)\\n    Name\\n    All Around\\n    Hoop\\n    Total\n",
              "Name: schema, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>schema</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[TABLES]\\nCoolBrands_branding_initiative:\\n    Rank (PK)\\n    2008\\n    2009\\n    2010\\n    2011\\n    2012\\n    2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[TABLES]\\nUnited_States_House_of_Representatives_elections_1998:\\n    District (PK)\\n    Incumbent\\n    Party\\n    First elected\\n    Results\\n    Candidates</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[TABLES]\\nCircuit_Trois_Rivières:\\n    Year (PK)\\n    Date\\n    Driver\\n    Team\\n    Distance/Duration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[TABLES]\\n1987_World_Rhythmic_Gymnastics_Championships:\\n    Place (PK)\\n    Name\\n    All Around\\n    Hoop\\n    Total</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[TABLES]\\nCentral_Murray_Football_League:\\n    Central Murray (PK)\\n    Wins\\n    Byes\\n    Losses\\n    Draws\\n    Against</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[TABLES]\\nCashmere_Mafia:\\n    Episode (PK)\\n    Rating\\n    Share\\n    Rating/Share (18-49)\\n    Viewers (millions)\\n    Rank (timeslot)\\n    Rank (night)\\n    Rank (week)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[TABLES]\\n2008_Brazilian_Grand_Prix:\\n    Driver (PK)\\n    Constructor\\n    Laps\\n    Time/Retired\\n    Grid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[TABLES]\\nUkraine_in_the_Eurovision_Song_Contest:\\n    Year(s) (PK)\\n    Television commentator\\n    Dual Television commentator\\n    Radio commentator\\n    Spokesperson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[TABLES]\\n193940_New_York_Rangers_season:\\n    Game (PK)\\n    February\\n    Opponent\\n    Score\\n    Record</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[TABLES]\\n1987_World_Rhythmic_Gymnastics_Championships:\\n    Place (PK)\\n    Name\\n    All Around\\n    Hoop\\n    Total</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.set_option(\"display.max_rows\", None)   # 不省略行\n",
        "pd.set_option(\"display.max_columns\", None)  # 不省略列\n",
        "pd.set_option(\"display.max_colwidth\", None) # 不省略内容长度\n",
        "df = pd.read_json(\"training_data/wikisql_train.jsonl\", lines=True)\n",
        "df['schema'][0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDcED79AhM2n"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JadS1GVqLAD_"
      },
      "source": [
        "### Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3qQ5GvILAEA",
        "outputId": "31958a3f-ffee-4433-e0ed-9ceb62c67e99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets peft accelerate bitsandbytes torch wandb --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdMHfbZ0lgEM",
        "outputId": "331ef4f3-46d3-4000-b681-54836ef708b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_train.txt (line 5)) (2.9.0+cu126)\n",
            "Requirement already satisfied: transformers>=4.36.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_train.txt (line 6)) (4.57.3)\n",
            "Requirement already satisfied: datasets>=2.14.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_train.txt (line 7)) (4.0.0)\n",
            "Requirement already satisfied: peft>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_train.txt (line 10)) (0.18.0)\n",
            "Requirement already satisfied: bitsandbytes>=0.41.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_train.txt (line 13)) (0.49.0)\n",
            "Requirement already satisfied: wandb>=0.15.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_train.txt (line 20)) (0.23.1)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_train.txt (line 23)) (4.67.1)\n",
            "Requirement already satisfied: sentence-transformers>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_train.txt (line 26)) (5.1.2)\n",
            "Requirement already satisfied: sqlparse>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_train.txt (line 29)) (0.5.4)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_train.txt (line 32)) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from -r requirements_train.txt (line 33)) (2.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->-r requirements_train.txt (line 5)) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements_train.txt (line 6)) (0.36.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements_train.txt (line 6)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements_train.txt (line 6)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements_train.txt (line 6)) (2025.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements_train.txt (line 6)) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements_train.txt (line 6)) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.36.0->-r requirements_train.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.0->-r requirements_train.txt (line 7)) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.0->-r requirements_train.txt (line 7)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.0->-r requirements_train.txt (line 7)) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.14.0->-r requirements_train.txt (line 7)) (0.70.16)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft>=0.7.0->-r requirements_train.txt (line 10)) (5.9.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from peft>=0.7.0->-r requirements_train.txt (line 10)) (1.12.0)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.15.0->-r requirements_train.txt (line 20)) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.15.0->-r requirements_train.txt (line 20)) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb>=0.15.0->-r requirements_train.txt (line 20)) (4.5.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.15.0->-r requirements_train.txt (line 20)) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.15.0->-r requirements_train.txt (line 20)) (2.12.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb>=0.15.0->-r requirements_train.txt (line 20)) (2.47.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=2.2.0->-r requirements_train.txt (line 26)) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=2.2.0->-r requirements_train.txt (line 26)) (1.16.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers>=2.2.0->-r requirements_train.txt (line 26)) (11.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements_train.txt (line 33)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements_train.txt (line 33)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->-r requirements_train.txt (line 33)) (2025.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements_train.txt (line 7)) (3.13.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.15.0->-r requirements_train.txt (line 20)) (4.0.12)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.36.0->-r requirements_train.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.15.0->-r requirements_train.txt (line 20)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.15.0->-r requirements_train.txt (line 20)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3->wandb>=0.15.0->-r requirements_train.txt (line 20)) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements_train.txt (line 33)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.36.0->-r requirements_train.txt (line 6)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.36.0->-r requirements_train.txt (line 6)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.36.0->-r requirements_train.txt (line 6)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers>=4.36.0->-r requirements_train.txt (line 6)) (2025.11.12)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->-r requirements_train.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->-r requirements_train.txt (line 5)) (3.0.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers>=2.2.0->-r requirements_train.txt (line 26)) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers>=2.2.0->-r requirements_train.txt (line 26)) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements_train.txt (line 7)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements_train.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements_train.txt (line 7)) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements_train.txt (line 7)) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements_train.txt (line 7)) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements_train.txt (line 7)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=2.14.0->-r requirements_train.txt (line 7)) (1.22.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.15.0->-r requirements_train.txt (line 20)) (5.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements_train.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx6eHeYbT_fk",
        "outputId": "188e062c-f5b1-4020-bff3-fdef968646bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers: 4.57.3\n",
            "peft: 0.18.0\n",
            "accelerate: 1.12.0\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "import peft\n",
        "import accelerate\n",
        "\n",
        "print(f\"transformers: {transformers.__version__}\")\n",
        "print(f\"peft: {peft.__version__}\")\n",
        "print(f\"accelerate: {accelerate.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xnsh6LQasreh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    BitsAndBytesConfig,\n",
        ")\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    prepare_model_for_kbit_training,\n",
        "    TaskType,\n",
        ")\n",
        "\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJVaBo-grHPe"
      },
      "source": [
        "### GPU Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aowbmeDWnwUV",
        "outputId": "89063f3c-75ee-48cb-d970-ffc5983cca8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "GPU INFORMATION\n",
            "============================================================\n",
            "✓ CUDA available: True\n",
            "  GPU: NVIDIA A100-SXM4-40GB\n",
            "  Memory: 42.47 GB\n",
            "  CUDA Version: 12.6\n",
            "\n",
            " Recommended config: large_gpu (more LoRA capacity)\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"GPU INFORMATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"✓ CUDA available: True\")\n",
        "    print(f\"  GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    props = torch.cuda.get_device_properties(0)\n",
        "    total_mem = props.total_memory / 1e9\n",
        "    print(f\"  Memory: {total_mem:.2f} GB\")\n",
        "    print(f\"  CUDA Version: {torch.version.cuda}\")\n",
        "\n",
        "    # Recommend config based on VRAM\n",
        "    if total_mem < 12:\n",
        "        print(f\"\\n  Recommended config: small_gpu (4-bit quantization)\")\n",
        "    elif total_mem < 24:\n",
        "        print(f\"\\n Recommended config: default\")\n",
        "    else:\n",
        "        print(f\"\\n Recommended config: large_gpu (more LoRA capacity)\")\n",
        "else:\n",
        "    print(\"✗ CUDA not available - Training will be VERY slow on CPU\")\n",
        "\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOOERWzPLAEB"
      },
      "source": [
        "### Configuration\n",
        "\n",
        "Define hyperparameters and LoRA configuration. (No need to run this cell if config.json already good.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIQQtsnhBlXB",
        "outputId": "0a52b067-6b21-4dcc-9747-28af2cdcf902"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configuration saved to config.json\n",
            "  Model: Qwen/Qwen2.5-7B-Instruct\n",
            "  LoRA rank: 16, alpha: 32\n",
            "  Batch size: 1 x 16 = 16 effective\n",
            "  Training: 0 epoch WikiSQL + 2 epochs Spider\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import sys\n",
        "sys.path.insert(0, '.')  # Add project root to path\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURATION - Edit values below, then run this cell to save\n",
        "# =============================================================================\n",
        "\n",
        "CONFIG = {\n",
        "    \"model\": {\n",
        "        \"model_name\": \"Qwen/Qwen2.5-7B-Instruct\",  # or \"microsoft/Phi-3.5-mini-instruct\"\n",
        "        \"load_in_4bit\": True,   # Recommended for <16GB VRAM\n",
        "        \"load_in_8bit\": False,\n",
        "    },\n",
        "    \"lora\": {\n",
        "    \"r\": 16,\n",
        "    \"alpha\": 32,\n",
        "    \"dropout\": 0.1,\n",
        "    \"target_modules\": [\n",
        "      \"q_proj\",\n",
        "      \"k_proj\",\n",
        "      \"v_proj\",\n",
        "      \"o_proj\",\n",
        "      \"gate_proj\",\n",
        "      \"up_proj\",\n",
        "      \"down_proj\"\n",
        "    ]\n",
        "    },\n",
        "    \"training\": {\n",
        "        \"wikisql_epochs\": 0,\n",
        "        \"spider_epochs\": 2,\n",
        "        \"batch_size\": 1,\n",
        "        \"gradient_accumulation\": 16,\n",
        "        \"learning_rate\": 0.00005,\n",
        "        \"lr_scheduler\": \"cosine\",\n",
        "        \"warmup_ratio\": 0.1,\n",
        "        \"max_seq_length\": 1024,\n",
        "        \"gradient_checkpointing\": True,\n",
        "        \"use_bf16\": True,\n",
        "        \"use_fp16\": False,\n",
        "    },\n",
        "    \"data\": {\n",
        "        \"data_dir\": \"./training_data\",\n",
        "        \"output_dir\": \"./checkpoints\",\n",
        "        \"max_train_samples\": None,  # None = use all\n",
        "        \"max_eval_samples\": 500,\n",
        "    },\n",
        "    \"wandb\": {\n",
        "        \"enabled\": True,\n",
        "        \"project\": \"nl2sql-finetuning\",\n",
        "        \"run_name\": None,  # Auto-generated if None\n",
        "    },\n",
        "    \"save\": {\n",
        "        \"strategy\": \"epoch\",\n",
        "        \"total_limit\": 5,\n",
        "    },\n",
        "}\n",
        "\n",
        "# Save configuration to JSON file\n",
        "with open('config.json', 'w') as f:\n",
        "    json.dump(CONFIG, f, indent=2)\n",
        "\n",
        "print(\"Configuration saved to config.json\")\n",
        "print(f\"  Model: {CONFIG['model']['model_name']}\")\n",
        "print(f\"  LoRA rank: {CONFIG['lora']['r']}, alpha: {CONFIG['lora']['alpha']}\")\n",
        "print(f\"  Batch size: {CONFIG['training']['batch_size']} x {CONFIG['training']['gradient_accumulation']} = {CONFIG['training']['batch_size'] * CONFIG['training']['gradient_accumulation']} effective\")\n",
        "print(f\"  Training: {CONFIG['training']['wikisql_epochs']} epoch WikiSQL + {CONFIG['training']['spider_epochs']} epochs Spider\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EptSkakBlXB"
      },
      "source": [
        "### Load Datasets & Run Training\n",
        "\n",
        "Using encapsulated functions from `training_utils.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlS_Sh9dBlXB",
        "outputId": "479cd08b-8cad-4140-f7d1-b555a957f045"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training utilities imported!\n"
          ]
        }
      ],
      "source": [
        "from scripts.training_utils import (\n",
        "    TrainingConfig,\n",
        "    load_config_from_json,\n",
        "    save_config_to_json,\n",
        "    print_config,\n",
        "    load_datasets,\n",
        "    show_sample_examples,\n",
        "    load_model_and_tokenizer,\n",
        "    setup_lora,\n",
        "    print_model_parameters,\n",
        "    init_wandb,\n",
        "    train_phase1_wikisql,\n",
        "    train_phase2_spider,\n",
        "    finish_training,\n",
        ")\n",
        "print(\"Training utilities imported!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhXvf75LBlXB",
        "outputId": "d8451b2b-cae1-4f7e-8163-856aff05974d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "CONFIGURATION\n",
            "============================================================\n",
            "\n",
            "Model: Qwen/Qwen2.5-7B-Instruct\n",
            "  4-bit: True, 8-bit: False\n",
            "\n",
            "LoRA:\n",
            "  Rank: 16, Alpha: 32, Dropout: 0.1\n",
            "  Target modules: ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj']\n",
            "\n",
            "Training:\n",
            "  Batch size: 1 x 16 = 16 effective\n",
            "  Learning rate: 5e-05, Scheduler: cosine\n",
            "  Epochs: 0 WikiSQL + 2 Spider\n",
            "\n",
            "Paths:\n",
            "  Data: ./training_data\n",
            "  Output: ./checkpoints\n",
            "\n",
            "WandB: Enabled\n",
            "  Project: nl2sql-finetuning\n"
          ]
        }
      ],
      "source": [
        "# Load configuration from JSON file\n",
        "config = load_config_from_json('config.json')\n",
        "print_config(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zZBMg6UBlXB",
        "outputId": "6eaf4d41-7181-4278-cd60-49fb575fff03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "DATASET INFORMATION\n",
            "============================================================\n",
            "\n",
            " WikiSQL Dataset:\n",
            "   Train samples: 1,722\n",
            "   Dev samples:   399\n",
            "   Columns: ['input', 'schema', 'question', 'output', 'sql', 'dataset', 'table_id', 'split']\n",
            "\n",
            " Spider Dataset:\n",
            "   Train samples: 7,000\n",
            "   Dev samples:   1,034\n",
            "   Columns: ['input', 'schema', 'question', 'output', 'sql', 'dataset', 'db_id', 'split', 'num_tables', 'has_join']\n",
            "   Multi-table: 7,000 (100.0%)\n",
            "   With JOIN:   2,783 (39.8%)\n",
            "\n",
            "============================================================\n",
            "============================================================\n",
            "SAMPLE EXAMPLES\n",
            "============================================================\n",
            "\n",
            " WikiSQL Example:\n",
            "Question: What is the highest rank of the 2009 xbox?\n",
            "SQL: SELECT MAX(\"Rank\") FROM \"table\" WHERE \"2009\" = 'xbox'\n",
            "\n",
            "Schema preview:\n",
            "[TABLES]\n",
            "CoolBrands_branding_initiative:\n",
            "    Rank (PK)\n",
            "    2008\n",
            "    2009\n",
            "    2010\n",
            "    2011\n",
            "    2012\n",
            "    2013\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            " Spider Example:\n",
            "Question: How many heads of the departments are older than 56 ?\n",
            "SQL: SELECT count(*) FROM head WHERE age  >  56\n",
            "Database: department_management\n",
            "\n",
            "Schema preview:\n",
            "[DATABASE]\n",
            "department_management\n",
            "\n",
            "[TABLES]\n",
            "department:\n",
            "    Department_ID (PK)\n",
            "    Name\n",
            "    Creation\n",
            "    Ranking\n",
            "    Budget_in_Billions\n",
            "    Num_Employees\n",
            "head:\n",
            "    head_ID (PK)\n",
            "    name\n",
            "    born_state\n",
            "    age\n",
            "management:\n",
            "    department_ID (PK, FK)\n",
            "    head_ID (FK)\n",
            "    temporary_acting\n",
            "\n",
            "[FOREIGN KEYS]\n",
            "management.head_ID -> head.head_ID\n",
            "management.department_ID -> department.Department_ID\n"
          ]
        }
      ],
      "source": [
        "# Load datasets\n",
        "wikisql_train, wikisql_dev, spider_train, spider_dev = load_datasets(config.data_dir)\n",
        "show_sample_examples(wikisql_train, spider_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656,
          "referenced_widgets": [
            "7c9b3f46eac041039a8fe5ab24073ec6",
            "98200a97af8243bea3d7b0d3dcf79b8b",
            "08efbbfb69dd441593b613d523434c00",
            "af70e15d92254832a589846024eb71f9",
            "326024b379644b8d87cea1d2fc82dd35",
            "b00031de80e04c5ba236c355700e1e58",
            "5b56ee8964c94946a6928f102230878e",
            "317794710a9a4c5bba69124f1a9c2b1b",
            "2ce9e00f6a2040189b998a1357a635bd",
            "b28357c870f444a0b3be4029d64fdb67",
            "18a33542e0de4530ba383306ee188216"
          ]
        },
        "id": "58qQGgr5BlXB",
        "outputId": "aafe7f18-af5a-4db3-cabb-c7593a0c077a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "LOADING MODEL\n",
            "============================================================\n",
            "\n",
            "Model: Qwen/Qwen2.5-7B-Instruct\n",
            "Using 4-bit quantization (QLoRA)\n",
            "\n",
            "Loading tokenizer...\n",
            "Loading model (this may take a few minutes)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c9b3f46eac041039a8fe5ab24073ec6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Model loaded!\n",
            "============================================================\n",
            "CONFIGURING LoRA\n",
            "============================================================\n",
            "\n",
            "LoRA Configuration:\n",
            "   Rank (r):        16\n",
            "   Alpha:           32\n",
            "   Dropout:         0.1\n",
            "   Target modules:  ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj']\n",
            "\n",
            " LoRA adapters added!\n",
            "============================================================\n",
            "MODEL PARAMETERS (AFTER LoRA)\n",
            "============================================================\n",
            "trainable params: 40,370,176 || all params: 7,655,986,688 || trainable%: 0.5273\n",
            "\n",
            " Detailed Parameter Count:\n",
            "   Total parameters:       4,393,342,464 (4.39B)\n",
            "   Trainable parameters:      40,370,176 (40.37M)\n",
            "   Frozen parameters:      4,352,972,288 (4.35B)\n",
            "   Trainable %:                  0.9189%\n",
            "\n",
            " LoRA Adapter Size:\n",
            "   LoRA parameters:           40,370,176 (40.37M)\n"
          ]
        }
      ],
      "source": [
        "# Load model and setup LoRA\n",
        "model, tokenizer = load_model_and_tokenizer(config)\n",
        "model = setup_lora(model, config)\n",
        "print_model_parameters(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "AroWptSrBlXB",
        "outputId": "c163a1d6-c803-43ce-a3c0-2c5693e2d36b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">nl2sql_20251212_222804</strong> at: <a href='https://wandb.ai/rynnefan-university-of-michigan/nl2sql-finetuning/runs/daopidnd' target=\"_blank\">https://wandb.ai/rynnefan-university-of-michigan/nl2sql-finetuning/runs/daopidnd</a><br> View project at: <a href='https://wandb.ai/rynnefan-university-of-michigan/nl2sql-finetuning' target=\"_blank\">https://wandb.ai/rynnefan-university-of-michigan/nl2sql-finetuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251212_222805-daopidnd/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/graphNL2SQL/wandb/run-20251212_222905-1x45rd2f</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rynnefan-university-of-michigan/nl2sql-finetuning/runs/1x45rd2f' target=\"_blank\">nl2sql_20251212_222905</a></strong> to <a href='https://wandb.ai/rynnefan-university-of-michigan/nl2sql-finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/rynnefan-university-of-michigan/nl2sql-finetuning' target=\"_blank\">https://wandb.ai/rynnefan-university-of-michigan/nl2sql-finetuning</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/rynnefan-university-of-michigan/nl2sql-finetuning/runs/1x45rd2f' target=\"_blank\">https://wandb.ai/rynnefan-university-of-michigan/nl2sql-finetuning/runs/1x45rd2f</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " WandB initialized! Run: nl2sql_20251212_222905\n"
          ]
        }
      ],
      "source": [
        "# Initialize WandB\n",
        "run_name = init_wandb(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PbnuthjBlXB"
      },
      "source": [
        "### Phase 1: WikiSQL Warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHPH0qzwBlXB",
        "outputId": "40610de7-d99e-420e-9bea-bc81771ae98e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping Phase 1 (WikiSQL not available or epochs=0)\n"
          ]
        }
      ],
      "source": [
        "# Phase 1: WikiSQL Warmup Training\n",
        "train_phase1_wikisql(model, tokenizer, wikisql_train, wikisql_dev, config, run_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sf5kX1fUBlXB"
      },
      "source": [
        "### Phase 2: Spider Main Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402,
          "referenced_widgets": [
            "f02b1187a2b848729a9c7814cbf4dfd7",
            "18f5fda2c8f840d2af1e7f5a10103adc",
            "f58069c8b34d41259a8d97de33a21141",
            "18344a11e19c4efa8a357358836be615",
            "f74665056f4e4ea2bc64d52d7904f845",
            "5ecf2b3e1f884fb6a928ebf7aba3e33d",
            "0d6e38ec649d4ffeb94e954fa28c530a",
            "f44b7087e850463d8bb7d586b5716dcf",
            "770ece026e8a40e6ba00817445b60894",
            "ecff84c7c11e41fab01eb41f1f1ae029",
            "d5a083132b704fdcb30ae7bb0fa8c1cd",
            "b1ce86cfb8164904b86c46037fd5b598",
            "1704043767444af0aacf64b674164695",
            "b8eb8cbb84e14975ade21bb4ccbf652e",
            "2398e02563754d8499095eff040f96a3",
            "1fddffaa1d6d4f86bb65797595c5ea63",
            "56dc1006f5374e0aa4bf2b1288358cca",
            "98f7fbd1e9a14bd49223a75f77af1130",
            "e201b6f8508c46f59a6de0870900a2b0",
            "bbdc42305b564dc5b1caaa4632fd2fa9",
            "f274960d99ba415da539ee2963d562f1",
            "9508d92d50de40728d93e34347dd59b0"
          ]
        },
        "id": "Bcj8SjKaBlXB",
        "outputId": "2d73d8dc-d470-498e-c2f1-b76777b98f33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 2: Spider Main Training\n",
            "============================================================\n",
            "\n",
            "Preparing Spider data...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing Spider train:   0%|          | 0/7000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f02b1187a2b848729a9c7814cbf4dfd7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Tokenizing Spider eval:   0%|          | 0/500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1ce86cfb8164904b86c46037fd5b598"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/graphNL2SQL/scripts/training_utils.py:812: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Spider Dataset Ready:\n",
            "   Train: 7,000 samples\n",
            "   Eval:  500 samples\n",
            "\n",
            " Starting Phase 2 training...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='8' max='876' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  8/876 01:03 < 2:33:09, 0.09 it/s, Epoch 0.02/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Phase 2: Spider Main Training\n",
        "trainer = train_phase2_spider(model, tokenizer, spider_train, spider_dev, config, run_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDOQKqOcBlXB"
      },
      "source": [
        "### Finish Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xkUvap1HLAEH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "outputId": "5e2bc07d-334d-4602-d33b-d56eb79d5e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to ./checkpoints/phase2_spider/final\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▁▅██</td></tr><tr><td>eval/runtime</td><td>▁█▇▇</td></tr><tr><td>eval/samples_per_second</td><td>▂▁█▇</td></tr><tr><td>eval/steps_per_second</td><td>▂▁█▇</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▂█▁▁▁▂▃▄▃▂▂▄▂▁▂▁▁▁▁▁▁▁▂▂▂▁▁▁▁▁▁▁▁▁▂▂▁▂▂▁</td></tr><tr><td>train/learning_rate</td><td>▇▅▃▂▃▇███████▇▇▇▇▆▆▆▅▄▄▄▃▃▃▃▃▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▃▃▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.20075</td></tr><tr><td>eval/runtime</td><td>86.1832</td></tr><tr><td>eval/samples_per_second</td><td>5.802</td></tr><tr><td>eval/steps_per_second</td><td>5.802</td></tr><tr><td>total_flos</td><td>7.62577533769089e+17</td></tr><tr><td>train/epoch</td><td>2.50057</td></tr><tr><td>train/global_step</td><td>1095</td></tr><tr><td>train/grad_norm</td><td>0.23363</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0734</td></tr><tr><td>+4</td><td>...</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">nl2sql_20251212_180714</strong> at: <a href='https://wandb.ai/rynnefan-university-of-michigan/nl2sql-finetuning/runs/zpguzcwo' target=\"_blank\">https://wandb.ai/rynnefan-university-of-michigan/nl2sql-finetuning/runs/zpguzcwo</a><br> View project at: <a href='https://wandb.ai/rynnefan-university-of-michigan/nl2sql-finetuning' target=\"_blank\">https://wandb.ai/rynnefan-university-of-michigan/nl2sql-finetuning</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251212_180732-zpguzcwo/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WandB run finished. Check your dashboard for loss graphs!\n"
          ]
        }
      ],
      "source": [
        "# Save the final model\n",
        "# Use output directory from config\n",
        "OUTPUT_DIR = config.output_dir + \"/phase2_spider/final\"\n",
        "\n",
        "trainer.save_model(OUTPUT_DIR)\n",
        "tokenizer.save_pretrained(OUTPUT_DIR)\n",
        "print(f\"Model saved to {OUTPUT_DIR}\")\n",
        "\n",
        "# Finish WandB run\n",
        "import wandb\n",
        "if wandb.run:\n",
        "    wandb.finish()\n",
        "    print(\"WandB run finished. Check your dashboard for loss graphs!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UOu1bmI1ND1"
      },
      "source": [
        "### Download to local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "cJyW-sRa1Opc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "afcbd302-72c7-40c2-bd0f-45bea25f63c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Creating zip: checkpoints/phase2_spider/checkpoint-438\n",
            "   Size: 216.9 MB\n",
            " Downloading...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_01c1d337-f212-4539-8af3-24005693ad67\", \"checkpoint-438_lora_adapter.zip\", 227433829)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import shutil\n",
        "DOWNLOAD_PATH = \"./checkpoints/phase2_spider/checkpoint-438\"\n",
        "\n",
        "def zip_and_download(model_path):\n",
        "    model_path = Path(model_path)\n",
        "    if not model_path.exists():\n",
        "        print(f\" Path not found: {model_path}\")\n",
        "        return\n",
        "\n",
        "    zip_name = f\"{model_path.name}_lora_adapter\"\n",
        "    zip_path = f\"/tmp/{zip_name}\"\n",
        "\n",
        "    print(f\" Creating zip: {model_path}\")\n",
        "    shutil.make_archive(zip_path, 'zip', model_path.parent, model_path.name)\n",
        "\n",
        "    zip_file = f\"{zip_path}.zip\"\n",
        "    print(f\"   Size: {os.path.getsize(zip_file)/(1024*1024):.1f} MB\")\n",
        "\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        print(\" Downloading...\")\n",
        "        files.download(zip_file)\n",
        "    except ImportError:\n",
        "        print(f\"\\n Download manually: {zip_file}\")\n",
        "\n",
        "zip_and_download(DOWNLOAD_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7pwWq2MBlXC"
      },
      "source": [
        "## Testing\n",
        "\n",
        "Using encapsulated functions from `testing_utils.py`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "HxHlrbrXBlXC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cb3b4f7-35bc-4607-8f63-1a68ffc41ef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing utilities imported (including Execution Match and EGD)!\n"
          ]
        }
      ],
      "source": [
        "from scripts.testing_utils import (\n",
        "    generate_sql,\n",
        "    load_finetuned_model,\n",
        "    # Evaluation functions\n",
        "    evaluate_model,              # Exact Match only\n",
        "    evaluate_with_execution,     # Exact Match + Execution Match\n",
        "    show_evaluation_examples,\n",
        "    # Testing functions\n",
        "    run_quick_test,\n",
        "    run_interactive_test,\n",
        "    test_with_university_schema,\n",
        "    test_with_ecommerce_schema,\n",
        "    UNIVERSITY_SCHEMA,\n",
        "    ECOMMERCE_SCHEMA,\n",
        "    SAMPLE_QUESTIONS,\n",
        "    # EGD functions\n",
        "    generate_sql_with_egd,\n",
        "    evaluate_with_egd,\n",
        ")\n",
        "print(\"Testing utilities imported (including Execution Match and EGD)!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO5wWOi4BlXC"
      },
      "source": [
        "### Load Fine-tuned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "fFWliojVBlXC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "21138514f93744acb8c0769aa78def25",
            "a6ceaf22090e4b209eb98e5fed02313e",
            "b44d0108018249688a28774e5274e18c",
            "0a11ece004704644b28e5d40e84dc7a5",
            "a9a2c85dfa9f4ba1bc8928fc48a15f6c",
            "34426527ef8542e89cef87d099bebc3a",
            "43d072248ac64801b6ca1e0a0e10ec80",
            "a84fff9b5cfc4ecfab904acca1510e16",
            "57a43c49b086402781441f7a3c6069de",
            "2474ccaf007f497ab9e022e55d1df263",
            "d0ccfea169764dbda2069c4df1296a6e"
          ]
        },
        "outputId": "fddb6dfb-e07f-4503-f804-b07fe234b0ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading base model: Qwen/Qwen2.5-7B-Instruct\n",
            "Using 4-bit quantization\n",
            "Loading tokenizer...\n",
            "Loading base model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21138514f93744acb8c0769aa78def25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading LoRA adapters...\n",
            " Model loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "CHECKPOINT_PATH = \"./checkpoints/phase2_spider/checkpoint-438\"\n",
        "\n",
        "# Load fine-tuned model (or use already loaded model from training)\n",
        "from pathlib import Path\n",
        "if Path(CHECKPOINT_PATH).exists():\n",
        "    eval_model, eval_tokenizer = load_finetuned_model(CHECKPOINT_PATH)\n",
        "else:\n",
        "    print(f\"Checkpoint not found: {CHECKPOINT_PATH}\")\n",
        "    print(\"Using model from training session...\")\n",
        "    eval_model, eval_tokenizer = model, tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4KJLNpjBlXC"
      },
      "source": [
        "### Quick Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "pnIuXdV0BlXC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "f5657e0b-6fd5-483e-a571-f7ce997c753f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "QUICK TEST\n",
            "============================================================\n",
            "\n",
            "Question: How many students are majoring in Computer Science?\n",
            "\n",
            "Schema:\n",
            "[TABLES]\n",
            "student:\n",
            "    id (PK)\n",
            "    name\n",
            "    age\n",
            "    major\n",
            "\n",
            "Generated SQL:\n",
            "SELECT count(*) FROM student WHERE major = \"Computer Science\"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SELECT count(*) FROM student WHERE major = \"Computer Science\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# Run quick test with default schema/question\n",
        "run_quick_test(eval_model, eval_tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qrVIYVWBlXF"
      },
      "source": [
        "### Evaluate on Spider Dev Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "xqVSiJoSBlXF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "outputId": "c9ca52ee-f88a-4c04-ae70-8b396c8d8c74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on 100 samples (Standard mode)...\n",
            "  [10/100] Accuracy: 70.0%\n",
            "  [20/100] Accuracy: 70.0%\n",
            "  [30/100] Accuracy: 66.7%\n",
            "  [40/100] Accuracy: 52.5%\n",
            "  [50/100] Accuracy: 48.0%\n",
            "  [60/100] Accuracy: 45.0%\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-500233991.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mspider_dev\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     eval_results = evaluate_model(\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0meval_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mspider_dev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/graphNL2SQL/scripts/testing_utils.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, tokenizer, eval_data, max_samples, max_new_tokens, verbose, use_egd, egd_candidates)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;31m# Generate SQL (with optional EGD)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         pred_sql = generate_sql(\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"question\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/graphNL2SQL/scripts/testing_utils.py\u001b[0m in \u001b[0;36mgenerate_sql\u001b[0;34m(model, tokenizer, question, schema, max_new_tokens, temperature, do_sample, use_egd, egd_candidates)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         outputs = model.generate(\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_new_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/peft_model.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2046\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_peft_forward_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2047\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial_peft_forward_args\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2048\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2049\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2050\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m         \u001b[0;31m# 9. Call generation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2564\u001b[0;31m         result = decoding_method(\n\u001b[0m\u001b[1;32m   2565\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2566\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2785\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2786\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2787\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict_passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;34m\"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         ```\"\"\"\n\u001b[0;32m--> 449\u001b[0;31m         outputs: BaseModelOutputWithPast = self.model(\n\u001b[0m\u001b[1;32m    450\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m                 \u001b[0;31m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m             hidden_states = decoder_layer(\n\u001b[0m\u001b[1;32m    385\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecoder_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_attention_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mdown_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdown_proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/peft/tuners/lora/bnb.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m                 \u001b[0;31m# As per Tim Dettmers, for 4bit, we need to defensively clone here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                 \u001b[0;31m# The reason is that in some cases, an error can occur that backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/bitsandbytes/nn/modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;31m# weights are cast automatically as Int8Params, but the bias has to be cast manually\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1949\u001b[0m     \u001b[0;31m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1950\u001b[0m     \u001b[0;31m# https://github.com/pytorch/pytorch/pull/115074\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1951\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Module\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1952\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_parameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_parameters\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Evaluate on Spider dev set\n",
        "EVAL_MAX_SAMPLES = 100  # Set to None for full evaluation\n",
        "USE_EGD = False          # Use Execution-Guided Decoding for better accuracy\n",
        "EGD_CANDIDATES = 5      # Number of candidates for EGD\n",
        "\n",
        "if spider_dev:\n",
        "    eval_results = evaluate_model(\n",
        "        eval_model, eval_tokenizer,\n",
        "        spider_dev,\n",
        "        max_samples=EVAL_MAX_SAMPLES,\n",
        "        use_egd=USE_EGD,\n",
        "        egd_candidates=EGD_CANDIDATES,\n",
        "    )\n",
        "\n",
        "    # Show example predictions\n",
        "    show_evaluation_examples(eval_results, num_correct=3, num_incorrect=3)\n",
        "else:\n",
        "    print(\"Spider dev data not loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT7s97cmBlXF"
      },
      "source": [
        "### Evaluate with Execution Match (EM + EX)\n",
        "\n",
        "Execution Match compares the actual execution results of predicted SQL vs gold SQL on a mock database. This is more forgiving than Exact Match since different SQL queries can produce the same results.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate with both Exact Match (EM) and Execution Match (EX)\n",
        "# This requires DuckDB: pip install duckdb\n",
        "# Uses EGD setting from above cell\n",
        "\n",
        "if spider_dev:\n",
        "    ex_results = evaluate_with_execution(\n",
        "        eval_model, eval_tokenizer,\n",
        "        spider_dev,\n",
        "        max_samples=EVAL_MAX_SAMPLES,\n",
        "        verbose=True,\n",
        "        use_egd=USE_EGD,\n",
        "        egd_candidates=EGD_CANDIDATES,\n",
        "    )\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"SUMMARY\" + (\" (with EGD)\" if USE_EGD else \"\"))\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Exact Match (EM):     {ex_results['exact_match_accuracy']:.2f}%\")\n",
        "    print(f\"Execution Match (EX): {ex_results['execution_match_accuracy']:.2f}%\")\n",
        "\n",
        "    # Show how many queries EX found correct that EM missed\n",
        "    ex_only = sum(1 for r in ex_results['results']\n",
        "                  if r['execution_match'] and not r['exact_match'])\n",
        "    if ex_only > 0:\n",
        "        print(f\"\\nEX found {ex_only} additional correct queries beyond EM!\")\n",
        "else:\n",
        "    print(\"Spider dev data not loaded.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I84cWauYhb26",
        "outputId": "feb21f2e-1c41-4133-d77b-dde70d3a1028"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating 100 samples with EM + EX (Standard mode)...\n",
            "------------------------------------------------------------\n",
            "  [10/100] EM: 80.0%, EX: 100.0%\n",
            "    [Debug] Both SQLs failed execution:\n",
            "      Gold error: Execution error: Binder Error: column \"average\" must appear in the GROUP BY clause or must be part o\n",
            "      Pred error: Execution error: Binder Error: No function matches the given name and argument types 'avg(VARCHAR)'.\n",
            "  [20/100] EM: 70.0%, EX: 85.0%\n",
            "    [Debug] Both SQLs failed execution:\n",
            "      Gold error: Execution error: Binder Error: column \"name\" must appear in the GROUP BY clause or must be part of a\n",
            "      Pred error: Execution error: Binder Error: column \"Name\" must appear in the GROUP BY clause or must be part of a\n",
            "    [Debug] Both SQLs failed execution:\n",
            "      Gold error: Execution error: Binder Error: Cannot compare values of type VARCHAR and type INTEGER_LITERAL - an e\n",
            "      Pred error: Execution error: Binder Error: Cannot compare values of type VARCHAR and type INTEGER_LITERAL - an e\n",
            "  [30/100] EM: 70.0%, EX: 80.0%\n",
            "  [40/100] EM: 55.0%, EX: 75.0%\n",
            "  [50/100] EM: 50.0%, EX: 72.0%\n",
            "  [60/100] EM: 45.0%, EX: 63.3%\n",
            "  [70/100] EM: 41.4%, EX: 61.4%\n",
            "  [80/100] EM: 37.5%, EX: 60.0%\n",
            "  [90/100] EM: 34.4%, EX: 57.8%\n",
            "  [100/100] EM: 31.0%, EX: 57.0%\n",
            "------------------------------------------------------------\n",
            "Final Results:\n",
            "  Exact Match (EM):     31.00% (31/100)\n",
            "  Execution Match (EX): 57.00% (57/100)\n",
            "  Execution Errors:     21 (schema parsing issues)\n",
            "\n",
            "  EX found 26 additional correct queries beyond EM\n",
            "\n",
            "============================================================\n",
            "SUMMARY\n",
            "============================================================\n",
            "Exact Match (EM):     31.00%\n",
            "Execution Match (EX): 57.00%\n",
            "\n",
            "EX found 26 additional correct queries beyond EM!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vuYB-lFBlXF"
      },
      "source": [
        "### Interactive Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "rB2gE2o8BlXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2357efd-92c8-41ee-dfb2-0924b2161056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "INTERACTIVE TESTING\n",
            "============================================================\n",
            "\n",
            "Schema:\n",
            "[DATABASE]\n",
            "university\n",
            "\n",
            "[TABLES]\n",
            "student:\n",
            "    student_id (PK)\n",
            "    name\n",
            "    age\n",
            "    department_id (FK)\n",
            "course:\n",
            "    course_id (PK)\n",
            "    title\n",
            "    credits\n",
            "enrollment:\n",
            "    enrollment_id (PK)\n",
            "    student_id (FK)\n",
            "    course_id (FK)\n",
            "    grade\n",
            "\n",
            "[FOREIGN KEYS]\n",
            "student.department_id -> department.department_id\n",
            "enrollment.student_id -> student.student_id\n",
            "enrollment.course_id -> course.course_id\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "[1] Q: How many students are there?\n",
            "    SQL: SELECT count(*) FROM student\n",
            "\n",
            "[2] Q: What are the names of students older than 20?\n",
            "    SQL: SELECT name FROM student WHERE age  >  20\n",
            "\n",
            "[3] Q: List all courses with more than 3 credits.\n",
            "    SQL: SELECT * FROM course WHERE credits  >  3\n",
            "\n",
            "[4] Q: Which students are enrolled in the Database course?\n",
            "    SQL: SELECT T1.name FROM student AS T1 JOIN enrollment AS T2 ON T1.student_id  =  T2.student_id JOIN course AS T3 ON T2.course_id  =  T3.course_id WHERE T3.title  =  \"Database\"\n",
            "\n",
            "[5] Q: What is the average age of students?\n",
            "    SQL: SELECT avg(age) FROM student\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'question': 'How many students are there?',\n",
              "  'sql': 'SELECT count(*) FROM student'},\n",
              " {'question': 'What are the names of students older than 20?',\n",
              "  'sql': 'SELECT name FROM student WHERE age  >  20'},\n",
              " {'question': 'List all courses with more than 3 credits.',\n",
              "  'sql': 'SELECT * FROM course WHERE credits  >  3'},\n",
              " {'question': 'Which students are enrolled in the Database course?',\n",
              "  'sql': 'SELECT T1.name FROM student AS T1 JOIN enrollment AS T2 ON T1.student_id  =  T2.student_id JOIN course AS T3 ON T2.course_id  =  T3.course_id WHERE T3.title  =  \"Database\"'},\n",
              " {'question': 'What is the average age of students?',\n",
              "  'sql': 'SELECT avg(age) FROM student'}]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# Test with university schema\n",
        "test_with_university_schema(eval_model, eval_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "hk42xqc1BlXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e735f7-913f-4916-f744-c45a6dd2a1ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "INTERACTIVE TESTING\n",
            "============================================================\n",
            "\n",
            "Schema:\n",
            "[DATABASE]\n",
            "ecommerce\n",
            "\n",
            "[TABLES]\n",
            "customer:\n",
            "    customer_id (PK)\n",
            "    name\n",
            "    email\n",
            "    city\n",
            "product:\n",
            "    product_id (PK)\n",
            "    name\n",
            "    price\n",
            "    category\n",
            "order:\n",
            "    order_id (PK)\n",
            "    customer_id (FK)\n",
            "    order_date\n",
            "    total_amount\n",
            "order_item:\n",
            "    item_id (PK)\n",
            "    order_id (FK)\n",
            "    product_id (FK)\n",
            "    quantity\n",
            "\n",
            "[FOREIGN KEYS]\n",
            "order.customer_id -> customer.customer_id\n",
            "order_item.order_id -> order.order_id\n",
            "order_item.product_id -> product.product_id\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "[1] Q: How many customers are from New York?\n",
            "    SQL: SELECT count(*) FROM customer WHERE city  =  \"New York\"\n",
            "\n",
            "[2] Q: What is the total revenue from all orders?\n",
            "    SQL: SELECT sum(total_amount) FROM \"public\".\"order\"\n",
            "\n",
            "[3] Q: List products with price greater than 100.\n",
            "    SQL: SELECT * FROM product WHERE price  >  100\n",
            "\n",
            "[4] Q: Which customers placed orders in 2024?\n",
            "    SQL: SELECT DISTINCT T1.name FROM customer AS T1 JOIN order AS T2 ON T1.customer_id = T2.customer_id WHERE YEAR(T2.order_date) = 2024\n",
            "\n",
            "[5] Q: What is the most popular product by quantity sold?\n",
            "    SQL: SELECT T1.name FROM product AS T1 JOIN order_item AS T2 ON T1.product_id  =  T2.product_id GROUP BY T1.name ORDER BY sum(T2.quantity) DESC LIMIT 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'question': 'How many customers are from New York?',\n",
              "  'sql': 'SELECT count(*) FROM customer WHERE city  =  \"New York\"'},\n",
              " {'question': 'What is the total revenue from all orders?',\n",
              "  'sql': 'SELECT sum(total_amount) FROM \"public\".\"order\"'},\n",
              " {'question': 'List products with price greater than 100.',\n",
              "  'sql': 'SELECT * FROM product WHERE price  >  100'},\n",
              " {'question': 'Which customers placed orders in 2024?',\n",
              "  'sql': 'SELECT DISTINCT T1.name FROM customer AS T1 JOIN order AS T2 ON T1.customer_id = T2.customer_id WHERE YEAR(T2.order_date) = 2024'},\n",
              " {'question': 'What is the most popular product by quantity sold?',\n",
              "  'sql': 'SELECT T1.name FROM product AS T1 JOIN order_item AS T2 ON T1.product_id  =  T2.product_id GROUP BY T1.name ORDER BY sum(T2.quantity) DESC LIMIT 1'}]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# Test with ecommerce schema\n",
        "test_with_ecommerce_schema(eval_model, eval_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "PSrlE2MwBlXG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6f466c5-9d85-4761-a253-9173db76faa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "INTERACTIVE TESTING\n",
            "============================================================\n",
            "\n",
            "Schema:\n",
            "[TABLES]\n",
            "employee:\n",
            "    id (PK)\n",
            "    name\n",
            "    department\n",
            "    salary\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "[1] Q: What is the average salary?\n",
            "    SQL: SELECT avg(salary) FROM employee\n",
            "\n",
            "[2] Q: List employees in the Engineering department.\n",
            "    SQL: SELECT * FROM employee WHERE department  =  \"Engineering\"\n",
            "\n",
            "[3] Q: Who has the highest salary?\n",
            "    SQL: SELECT name FROM employee ORDER BY salary DESC LIMIT 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'question': 'What is the average salary?',\n",
              "  'sql': 'SELECT avg(salary) FROM employee'},\n",
              " {'question': 'List employees in the Engineering department.',\n",
              "  'sql': 'SELECT * FROM employee WHERE department  =  \"Engineering\"'},\n",
              " {'question': 'Who has the highest salary?',\n",
              "  'sql': 'SELECT name FROM employee ORDER BY salary DESC LIMIT 1'}]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# Custom test - modify schema and questions as needed\n",
        "custom_schema = \"\"\"[TABLES]\n",
        "employee:\n",
        "    id (PK)\n",
        "    name\n",
        "    department\n",
        "    salary\"\"\"\n",
        "\n",
        "custom_questions = [\n",
        "    \"What is the average salary?\",\n",
        "    \"List employees in the Engineering department.\",\n",
        "    \"Who has the highest salary?\",\n",
        "]\n",
        "\n",
        "run_interactive_test(eval_model, eval_tokenizer, custom_schema, custom_questions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1mcGXFhLAEI"
      },
      "source": [
        "## Possible Improvement directions\n",
        "\n",
        "\n",
        "\n",
        "1. **Input Format**: WikiSQL model expects `translate English to SQL: <question> context: <columns>`\n",
        "\n",
        "2. **More Data**: The sample dataset is tiny. Use hundreds or thousands of examples for real training.\n",
        "\n",
        "3. **LoRA Rank**: Start with r=16. Increase to 32 or 64 if underfitting, decrease to 8 if overfitting.\n",
        "\n",
        "4. **Learning Rate**: 1e-4 to 3e-4 typically works well for LoRA."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "gpurun",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7c9b3f46eac041039a8fe5ab24073ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_98200a97af8243bea3d7b0d3dcf79b8b",
              "IPY_MODEL_08efbbfb69dd441593b613d523434c00",
              "IPY_MODEL_af70e15d92254832a589846024eb71f9"
            ],
            "layout": "IPY_MODEL_326024b379644b8d87cea1d2fc82dd35"
          }
        },
        "98200a97af8243bea3d7b0d3dcf79b8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b00031de80e04c5ba236c355700e1e58",
            "placeholder": "​",
            "style": "IPY_MODEL_5b56ee8964c94946a6928f102230878e",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "08efbbfb69dd441593b613d523434c00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_317794710a9a4c5bba69124f1a9c2b1b",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ce9e00f6a2040189b998a1357a635bd",
            "value": 4
          }
        },
        "af70e15d92254832a589846024eb71f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b28357c870f444a0b3be4029d64fdb67",
            "placeholder": "​",
            "style": "IPY_MODEL_18a33542e0de4530ba383306ee188216",
            "value": " 4/4 [00:15&lt;00:00,  3.79s/it]"
          }
        },
        "326024b379644b8d87cea1d2fc82dd35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b00031de80e04c5ba236c355700e1e58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b56ee8964c94946a6928f102230878e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "317794710a9a4c5bba69124f1a9c2b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ce9e00f6a2040189b998a1357a635bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b28357c870f444a0b3be4029d64fdb67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18a33542e0de4530ba383306ee188216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f02b1187a2b848729a9c7814cbf4dfd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18f5fda2c8f840d2af1e7f5a10103adc",
              "IPY_MODEL_f58069c8b34d41259a8d97de33a21141",
              "IPY_MODEL_18344a11e19c4efa8a357358836be615"
            ],
            "layout": "IPY_MODEL_f74665056f4e4ea2bc64d52d7904f845"
          }
        },
        "18f5fda2c8f840d2af1e7f5a10103adc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ecf2b3e1f884fb6a928ebf7aba3e33d",
            "placeholder": "​",
            "style": "IPY_MODEL_0d6e38ec649d4ffeb94e954fa28c530a",
            "value": "Tokenizing Spider train: 100%"
          }
        },
        "f58069c8b34d41259a8d97de33a21141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f44b7087e850463d8bb7d586b5716dcf",
            "max": 7000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_770ece026e8a40e6ba00817445b60894",
            "value": 7000
          }
        },
        "18344a11e19c4efa8a357358836be615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecff84c7c11e41fab01eb41f1f1ae029",
            "placeholder": "​",
            "style": "IPY_MODEL_d5a083132b704fdcb30ae7bb0fa8c1cd",
            "value": " 7000/7000 [00:04&lt;00:00, 1536.27 examples/s]"
          }
        },
        "f74665056f4e4ea2bc64d52d7904f845": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ecf2b3e1f884fb6a928ebf7aba3e33d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d6e38ec649d4ffeb94e954fa28c530a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f44b7087e850463d8bb7d586b5716dcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "770ece026e8a40e6ba00817445b60894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecff84c7c11e41fab01eb41f1f1ae029": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5a083132b704fdcb30ae7bb0fa8c1cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1ce86cfb8164904b86c46037fd5b598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1704043767444af0aacf64b674164695",
              "IPY_MODEL_b8eb8cbb84e14975ade21bb4ccbf652e",
              "IPY_MODEL_2398e02563754d8499095eff040f96a3"
            ],
            "layout": "IPY_MODEL_1fddffaa1d6d4f86bb65797595c5ea63"
          }
        },
        "1704043767444af0aacf64b674164695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56dc1006f5374e0aa4bf2b1288358cca",
            "placeholder": "​",
            "style": "IPY_MODEL_98f7fbd1e9a14bd49223a75f77af1130",
            "value": "Tokenizing Spider eval: 100%"
          }
        },
        "b8eb8cbb84e14975ade21bb4ccbf652e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e201b6f8508c46f59a6de0870900a2b0",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbdc42305b564dc5b1caaa4632fd2fa9",
            "value": 500
          }
        },
        "2398e02563754d8499095eff040f96a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f274960d99ba415da539ee2963d562f1",
            "placeholder": "​",
            "style": "IPY_MODEL_9508d92d50de40728d93e34347dd59b0",
            "value": " 500/500 [00:00&lt;00:00, 1661.01 examples/s]"
          }
        },
        "1fddffaa1d6d4f86bb65797595c5ea63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56dc1006f5374e0aa4bf2b1288358cca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98f7fbd1e9a14bd49223a75f77af1130": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e201b6f8508c46f59a6de0870900a2b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbdc42305b564dc5b1caaa4632fd2fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f274960d99ba415da539ee2963d562f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9508d92d50de40728d93e34347dd59b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21138514f93744acb8c0769aa78def25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6ceaf22090e4b209eb98e5fed02313e",
              "IPY_MODEL_b44d0108018249688a28774e5274e18c",
              "IPY_MODEL_0a11ece004704644b28e5d40e84dc7a5"
            ],
            "layout": "IPY_MODEL_a9a2c85dfa9f4ba1bc8928fc48a15f6c"
          }
        },
        "a6ceaf22090e4b209eb98e5fed02313e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34426527ef8542e89cef87d099bebc3a",
            "placeholder": "​",
            "style": "IPY_MODEL_43d072248ac64801b6ca1e0a0e10ec80",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b44d0108018249688a28774e5274e18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a84fff9b5cfc4ecfab904acca1510e16",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57a43c49b086402781441f7a3c6069de",
            "value": 4
          }
        },
        "0a11ece004704644b28e5d40e84dc7a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2474ccaf007f497ab9e022e55d1df263",
            "placeholder": "​",
            "style": "IPY_MODEL_d0ccfea169764dbda2069c4df1296a6e",
            "value": " 4/4 [00:16&lt;00:00,  3.94s/it]"
          }
        },
        "a9a2c85dfa9f4ba1bc8928fc48a15f6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34426527ef8542e89cef87d099bebc3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43d072248ac64801b6ca1e0a0e10ec80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a84fff9b5cfc4ecfab904acca1510e16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57a43c49b086402781441f7a3c6069de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2474ccaf007f497ab9e022e55d1df263": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0ccfea169764dbda2069c4df1296a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}